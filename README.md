# bce-scripts
## Инструменты
### 1. `shrink.py`

Основной скрипт, используемый для уменьшения размера `.csv` файла, полученного из инструмента для нахождения клонов. Это достигается удалением из списка пар клонов **дубликатов** и **вложенных конструкций**.

+ **Дубликаты** находятся с точностью до параметра `-t threshold`: 
    * 1.0 - только полностью совпадающие клоны; 
    * 0.7 - порог, используемый в *BigCloneEval* для проверки найденных клонов;
    * *0.0 - любые пересекающиеся пары клонов*

+ **Вложенные конструкции** - две пары клонов, в одной из которых оба блока полностью покрыты блоками второй пары клонов.

### 2. `get_classes.py`

Скрипт для разбиения набора пар клонов на *классы* (*кластеры*), путём нахождения компонент связности в графе, где вершины — блоки кодов, а рёбра — пары клонов.
Выводит классы в формате `{dir,fn,start,end;...}` в файл.

### 3. `make_full.py`

Скрипт для нахождения *классов* в наборе пар клонов, и дополнения этого набора новыми парами клонов, чтобы классы стали полными подграфами (кликами). 

Не стоит запускать на больших файлах (примерный размер итогового файла можно оценить с помощью предыдущего скрипта `get_classes.py` и его вывода о количестве рёбер в графе, который получился бы). 

### 4. `convert_nicad.py`

Скрипт для преобразования результата работы **NiCad7** в `.xml` формате, в `.csv` формат, необходимый для **BigCloneEval**.

### 5. `convert_ccs.sh`

Скрипт для преобразования результата работы **CCSTokener**, в формат, необходимый для **BigCloneEval**.

### 6. `subtract.py`

Скрипт для вычитания одного набора пар клонов из другого.

## Отчёты

В папке `reports` есть две директории: `mip6-mit50` и `mip10-mil10-mit50`. Они различаются парамаетрами **BigCloneEval**, с которыми его запускали.

### 1. `ccs.report`

**CCSTokener** в режиме `bcb`.

### 2. `ccs.shrink.report`

**CCSTokener** в режиме `bcb`, обработанный скриптом `shrink.py`.

### 3. `nicad7.report`

**NiCad7** с параметром `mip=6` (в `mip10-mil10-mit50` у **NiCad7** параметр `mip=10`).

### 4. `nicad7.shrink.report`

**NiCad7** с параметром `mip=6` (в `mip10-mil10-mit50` у **NiCad7** параметр `mip=10`), обработанный скриптом `shrink.py`.

### 5. `nicad7-ccs.report`

Отчёт по конкатенации двух наборов из `ccs.report` и `nicad7.report`.

### 6. `nicad7-ccs.shrink.report`

Отчёт по конкатенации двух наборов из `ccs.report` и `nicad7.report`, обработанный скриптом `shrink.py`.

## Использование на инструментах для нахождения клонов

### Использование `shrink.py` на *CCSTokener*

Из двух отчётов `ccs.report` и `ccs.shrink.report` можно видеть, что размёр результата работы уменьшился на 6.3%, при чём отчёт **BigCloneEval** совершенно не изменился (ни одно число). То есть `shrink.py` успешно чистит результат **CCSTokener** от лишних пар клонов.

### Использование `shrink.py` на *NiCad7*

Из двух отчётов `nicad7.report` и `nicad7.shrink.report` опять же видно, что отчёт **BigCloneEval** никак не изменился, однако количество пар клонов уменьшилось на 30%, то есть почти в полтора раза.

### Использование `shrink.py` для слияния результатов *CCSTokener* и *NiCad7*

После простой конкатенации `ccs.report` и `nicad7.report` (`nicad7-ccs.report`) у нас получается достаточно много пар клонов — 7 миллионов. Однако после запуска на этом файле `shrink.py` (`nicad7-ccs.shrink.report`) мы получаем гораздо меньше — 4.7 миллионов, то есть на 33% меньше чем после конкатенации, и чуть-чуть меньше, чем у **CCSTokener** без скрипта (на 3%).

Относительно `ccs.report` и `nicad7.report` отчёт **BigCloneEval** только улучшился (что логично, потому что мы объединили их результаты).

```
# ccs.report
-- Recall Per Clone Type (type: numDetected / numClones = recall) --
              Type-1: 24346 / 24371 = 0.9989741906364121
              Type-2: 3675 / 3703 = 0.9924385633270322
      Type-2 (blind): 257 / 262 = 0.9809160305343512
 Type-2 (consistent): 3418 / 3441 = 0.993315896541703
Very-Strongly Type-3: 3950 / 4019 = 0.98283155013685
     Strongly Type-3: 9792 / 10484 = 0.9339946585272797
    Moderatly Type-3: 32803 / 60999 = 0.5377629141461335
Weakly Type-3/Type-4: 129247 / 6543930 = 0.019750669704596473
```

```
# nicad7.report
-- Recall Per Clone Type (type: numDetected / numClones = recall) --
              Type-1: 24346 / 24371 = 0.9989741906364121
              Type-2: 3678 / 3703 = 0.9932487172562787
      Type-2 (blind): 259 / 262 = 0.9885496183206107
 Type-2 (consistent): 3419 / 3441 = 0.993606509735542
Very-Strongly Type-3: 3955 / 4019 = 0.9840756407066434
     Strongly Type-3: 7697 / 10484 = 0.7341663487218619
    Moderatly Type-3: 293 / 60999 = 0.004803357432089051
Weakly Type-3/Type-4: 7 / 6543930 = 1.0696935939106928E-6
```

```
# nicad7-ccs.shrink.report
-- Recall Per Clone Type (type: numDetected / numClones = recall) --
              Type-1: 24346 / 24371 = 0.9989741906364121
              Type-2: 3678 / 3703 = 0.9932487172562787
      Type-2 (blind): 259 / 262 = 0.9885496183206107
 Type-2 (consistent): 3419 / 3441 = 0.993606509735542
Very-Strongly Type-3: 3955 / 4019 = 0.9840756407066434
     Strongly Type-3: 9916 / 10484 = 0.9458222052651659
    Moderatly Type-3: 32821 / 60999 = 0.5380580009508352
Weakly Type-3/Type-4: 129254 / 6543930 = 0.019751739398190384
```

Итого мы смогли объединить результаты работы двух инструментов, не увеличив размер файла (относительно максимального из двух), и только улучшив показания **BigCloneEval**.

### Параметр threshold у `shrink.py`

Параметр `threshold` нужен, чтобы определять дубликаты с какой-то точностью, поэтому если сделать threshold меньше, то теоретически, будет удаляться больше дубликатов.

Однако, если запускать скрипт на результатах работы **CCSTokener** или **NiCad7** с разными значениями `threshold` (1.0, 0.7 или 0.5), то оказывается, что разницы никакой не будет. То есть эти инструменты для нахождения клонов могут оставить лишь точные дубликаты (буквально одинаковые строчки), но строчек, где, скажем, была бы разница в границах в 2-3 строки, нет. Поэтому запускать `shrink.py` стоит с значением `threshold` по умолчанию, то есть 1.0.

<!-- ### Использование `make_full.py` на *CCSTokener*

`make_full.py` дополняет набор пар клонов до такого, в котором все классы полностью включены в набор. Делать бы такое для полного набора клонов на `bcb_reduced`, найденных **CCSTokener** было бы очень затратно по памяти, потому что их там получилось бы примерно 3 миллиарда. Поэтому мы запускаем `make_full.py` на результате работы только на отдельных субдиректориях `bcb_reduced`, и смотрим отчёт **BigCloneEval** только по этим субдиректориям.

В качестве примера запустим **CCSTokener** на `bcb_reduced/4` и обработаем результат скриптом `make_full.py`. *To be continued...* -->